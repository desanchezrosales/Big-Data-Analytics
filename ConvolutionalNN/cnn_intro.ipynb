{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks\n",
    "We have been using **fully connected networks** (FCNs) to classify the MNIST dataset, and in the last assignment we designed a network which could do this with an accuracy of around 98%.   Convolutional Neural Networks, or Convnets, or CNNS (fake networks!), are another even more powerful tool for classifying images such as MNIST.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors?\n",
    "Check to see that the **kernel** is correct (Python 6.6/Conda 5.2).\n",
    "\n",
    "Check that you have the correct version of keras (2.2.4) and tensorflow-gpu (1.9.0).\n",
    "\n",
    "You can do this one of two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.2.4\n",
      "tensorflow 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "print(\"keras\",keras.__version__)\n",
    "print(\"tensorflow\",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info (60000, 28, 28) (60000,)\n",
      "Test info (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "short = False\n",
    "if short:\n",
    "    train_images = train_images[:7000,:]\n",
    "    train_labels = train_labels[:7000]\n",
    "    test_images = test_images[:3000,:]\n",
    "    test_labels = test_labels[:3000]\n",
    "#\n",
    "print(\"Train info\",train_images.shape, train_labels.shape)\n",
    "print(\"Test info\",test_images.shape, test_labels.shape)\n",
    "train_images = train_images.reshape((train_images.shape[0],28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((test_images.shape[0],28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels_cat = to_categorical(train_labels)\n",
    "test_labels_cat = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the test set using our previous network\n",
    "You might ask, what do Convnets do that FCNs can't?\n",
    "\n",
    "To understand this, let's take another look at our MNIST FCN.  If you have not already, examine and run the jupyter notebook in assignment10_prep called **train_fcn_model_mnist.ipynb**.   After you run this, you will have a stored version of the compiled and fit FCN called **fully_trained_model_fcn.h5**.\n",
    "\n",
    "**Then** you can run the code below (which loads in the network that train_fcn_model_mnist.ipynb trains).\n",
    "\n",
    "We should get around 98% (will vary depending on the randomly initialized weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "network_name = 'fully_trained_model_fcn.h5'\n",
    "trained_network = load_model(network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A method to get performance numbers\n",
    "The following method will be helpful later to get loss, accuracy, and the confusion matrix for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#\n",
    "# Used to implement the multi-dimensional counter we need in the performance class\n",
    "from collections import defaultdict\n",
    "def autovivify(levels=1, final=dict):\n",
    "    return (defaultdict(final) if levels < 2 else\n",
    "            defaultdict(lambda: autovivify(levels-1, final)))\n",
    "def getPerformance(network,images,labels_cat,labels):\n",
    "#\n",
    "# Get the overall performance for the test sample\n",
    "    loss, acc = network.evaluate(images,labels_cat)\n",
    "#\n",
    "# Get the individual predictions for each sample in the test set\n",
    "    predictions = network.predict(images)\n",
    "#\n",
    "# Get the max probabilites for each rows\n",
    "    probs = np.max(predictions, axis = 1)\n",
    "#\n",
    "# Get the predicted classes for each row\n",
    "    classes = np.argmax(predictions, axis = 1)\n",
    "#\n",
    "# Now loop over the first twenty samples and compare truth to prediction\n",
    "#print(\"Label\\t Pred\\t Prob\")\n",
    "#for label,cl,pr in zip(smear_labels[:20],classes[:20],probs[:20]):\n",
    "#    print(label,'\\t',cl,'\\t',round(pr,3))\n",
    "#\n",
    "# Get confustion matrix\n",
    "    cf = autovivify(2,int)\n",
    "    for label,cl in zip(labels,classes):\n",
    "        cf[label][cl] += 1\n",
    "#\n",
    "    return loss,acc,cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/step\n",
      "   Results\n",
      "   Loss,acc 0.0652 0.9811\n",
      "   True:  0 \t 971 \t 1 \t 2 \t 0 \t 1 \t 1 \t 2 \t 1 \t 1 \t 0\n",
      "   True:  1 \t 0 \t 1127 \t 1 \t 1 \t 0 \t 1 \t 2 \t 1 \t 2 \t 0\n",
      "   True:  2 \t 4 \t 2 \t 1011 \t 3 \t 2 \t 0 \t 3 \t 3 \t 3 \t 1\n",
      "   True:  3 \t 0 \t 0 \t 3 \t 988 \t 0 \t 6 \t 0 \t 2 \t 8 \t 3\n",
      "   True:  4 \t 0 \t 0 \t 2 \t 1 \t 971 \t 0 \t 5 \t 0 \t 1 \t 2\n",
      "   True:  5 \t 1 \t 0 \t 0 \t 3 \t 1 \t 881 \t 1 \t 0 \t 3 \t 2\n",
      "   True:  6 \t 3 \t 3 \t 1 \t 1 \t 3 \t 5 \t 938 \t 0 \t 4 \t 0\n",
      "   True:  7 \t 0 \t 6 \t 9 \t 0 \t 4 \t 0 \t 0 \t 1001 \t 5 \t 3\n",
      "   True:  8 \t 2 \t 1 \t 2 \t 4 \t 5 \t 5 \t 1 \t 3 \t 947 \t 4\n",
      "   True:  9 \t 1 \t 4 \t 0 \t 3 \t 16 \t 4 \t 0 \t 2 \t 3 \t 976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc,cf = getPerformance(trained_network,test_images,test_labels_cat,test_labels)\n",
    "print(\"   Results\")\n",
    "print(\"   Loss,acc\",round(loss,4),round(acc,4))\n",
    "for trueClass in range(10):\n",
    "    print(\"   True: \",trueClass,end=\"\")\n",
    "    for predClass in range(10):\n",
    "        print(\" \\t\",cf[trueClass][predClass],end=\"\")\n",
    "    print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we improve on this?\n",
    "When we ask about how we might improve on this performance, we should think about a few things:\n",
    "1.  How big is our network?   Does it scale to images larger than our 28x28x1 digit images?\n",
    "2.  How sensitive is our network to small (or even large) changes in our inputs?\n",
    "3.  Even if the previous two points are a problem, we can still ask if it is possible to improve our performance over the FCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big is our network\n",
    "Keras gives us a tool to get summary information about our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1_input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"dense_2/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trained_network.input)\n",
    "print(trained_network.output)\n",
    "print(trained_network.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Number of parameters\n",
    "Notice that the two layers are called **dense**: these are fully connected layers, meaning there is a connection from every output of one layer to every input of the next layer.   Here is how we get the parameter counts:\n",
    "1.  dense_1 (the \"_1\" is just a label from when the network was created, it has no significance): We have 784 inputs each connected to 400 hidden nodes: 784*400=313600 parameters, plus another 400 \"bias\" parameters (1 for each node) which gives us a total of 314,000 parameters for the hidden layer.\n",
    "2.  dense_2: we have 400 inputs (one each from the hidden layer) connected to 10 outputs: 400*10 + 10(bias)=4010 parameters for the output layer.\n",
    "\n",
    "So we have 318,010 total parameters for a network which is used to classify small 28x28x1 greyscale images.   If we went to megapixel color images, we would have 1000x1000x3 = 3,000,000 input pixels, and if we have a 400 node hidden layer (which is probably too small), we end up with more than 1.2 billion parameters.... this does not scale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to variations in the input\n",
    "The types of variations we want to consider include:\n",
    "1.  Shifts of the input image (up/down and/or right/left).\n",
    "2.  Scaling of the input image (making it bigger or smaller (still within the 28x28 pixel window).\n",
    "3.  Rotations of the input image.\n",
    "We could also include shearing of the input image, but for now lets just consider the first 3.   \n",
    "\n",
    "Keras includes a method for performing all of these operations on an image.   Let's define a method to do this, using a single image as an input, and also define a method to display the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.image as kpi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = kpi.ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "def transform_image(img,tx=0,ty=0,zoom=1.0,rotation=0.0,shear=0.0):\n",
    "    transform_parameters = {}\n",
    "    orig_image = np.array(img, copy=True).reshape(28,28,1)\n",
    "    transform_parameters['theta'] = rotation\n",
    "    transform_parameters['zx'] = zoom\n",
    "    transform_parameters['zy'] = zoom\n",
    "    transform_parameters['tx'] = tx\n",
    "    transform_parameters['ty'] = ty\n",
    "    transform_parameters['shear'] = shear\n",
    "    orig_image = image_datagen.apply_transform(x=orig_image, transform_parameters=transform_parameters)\n",
    "    \n",
    "    \n",
    "    return orig_image\n",
    "\n",
    "def plot_image(img):\n",
    "    one_image = img.reshape(28,28)\n",
    "    plt.imshow(one_image, cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Pick a random image from our test dataset, and do the following:\n",
    "1.  Rotate 45 degrees.\n",
    "2.  Rotate 45 degrees plus zoom out (make the digit smaller)\n",
    "3.  Rotate 45 degrees plus zoom out plus translate the image to the upper corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_images[7]\n",
    "transformed_image = transform_image(image,tx=0,ty=0,zoom=1.0,rotation=45,shear=0.0)\n",
    "plot_image(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_images[7]\n",
    "transformed_image = transform_image(image,tx=0.0,ty=0.0,zoom=2.0,rotation=45,shear=0.0)\n",
    "plot_image(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE2dJREFUeJzt3X+MHGd9x/H3xxdoKifQUDepZRsSqKmI0sppr4YqCIJC0AVVOEiAbAQKaopTCdNQaEtKEUShqCklSRG1Ui7EiouAkPIrJ2pqohAaQCS6dRolsd0UyzXJ2ZbdKxSCaTC2v/1j55Ldvd2ZvbvZnXnWn5e08s08z818vbK/ep5nnucZRQRmZilZVnUAZmYL5cRlZslx4jKz5DhxmVlynLjMLDlOXGaWHCcuM0uOE5eZJceJy8ySc8YwbyYpnCnNBucUEBFayjUmJiZidna2r7q7du3aGRETS7nfYiwpcUmaAD4BjAGfjogb8+ovA85cyg3NamKsoPzkUKKY7+kSrjE7O0uj0eirrqQVJdxywRaduCSNAVuBy4EZYFrSVETsKSs4M6tCACeqDiLXUlpc64F9EbEfQNKdwAbAicssaUE5bbfBWUriWgU82XI8A7y8s5KkzcBmgCV1vM1sSEa7xdUtD83bIyciJoFJgDHJe+iY1d5oJ64ZYE3L8Wrg0NLCMbPqjXbimgbWSroAOAhsBN5aSlRmVqERTlwRcULSFmAnzafD2yJid2mRmVXoxQXljz5VUOH5+cXLTy0kmiqMaOICiIgdwI6SYjGzWjgF/LzqIHINdea8maVghLuKZjbKnLjMLClucZlZcpy4zCw5pxjlJT9mNrLc4jJLTtE0Lc766/zyk9fkFh/juz3LluvKorsPmLuKZpYcJy4zS44Tl5klx4nLzJIz2hsJmtlIcovLzJITVPe6j/44cdnI+mRO2TcLfvcrBeWr9MHc8oOvzC/n2703Az4W+RsFL9egN0F3i8vMkuTEZWZJ8ZIfM0uOu4pmlhwnLjNLkhOXmSXFLS4zS44Tl1lPf1FQftMSr/+HcUXvMm7I/d1d+r3c8lcV3Hv5d/LLj92cMxfrvfnzuI7FHT3Lxsevz79xX/xU0cyS5BaXmSXFXUUzS44Tl5klx4nLzJLk3SHMLCl+qmhmyRnxrqKkAzTf5HQSOBER42UEZaPj2I9zCp+X/xKwu3V2bvnjBfe+VF/vWfatOCv3d383/i+3/Bj/kn/zT74pv/zd9+WX58r7b1vGXl3lJi5JE8AngDHg0xFxY0f5C4HtwK9kda6LiB151yyjxfWaiJgt4TpmVgvlJS5JY8BW4HJgBpiWNBURe1qqfRC4KyJulXQhsAM4P++6y0qJzsxGzIk+P4XWA/siYn9EHAfuBDZ01AngednPzwcOFV10qS2uAL4hKYBPRcTkEq9nZpVb0OD8CkmNluPJjjywCniy5XgGeHnHNa6nmUfeDSwHXlt006Umrksi4pCkc4F7JP1HRNzfWkHSZmAzlNP7NrNBW1BXcbZgbLvbf/vOxZibgDsi4iZJvw98RtJFEXGq10WX1FWMiEPZn0dpvl9gfZc6kxExHhHjTlxmKZhLXKV0FWeANS3Hq5nfFbwauAsgIr4HnAmsyLvoohOXpOVS87GPpOXA64DHFns9M6uT0hLXNLBW0gWSngtsBKY66jwBXAYg6WU0E9d/5110KV3F84CvqPmqpDOAz0XEvy7hemZWC+U9VYyIE5K2ADtpTnXYFhG7Jd0ANCJiCngfcJukP81u/o6I/He0qaC8VGNSnDm0u1kdHHtDTuHdBf/2Xp0/uLD8/tziXBcWlE/HOwtqFD2HmikoX927aFf+33tLzojSXcDRiCWNyoyP/3I0Gi/uq660Z1cV8zc9c97MOnjJj5klyYuszSwpI75W0cxGkROXmSXHicvMkuTEZaex5Z1TDVsc46P5v/xvBa/p+lD+U/8/+kjvsh/k3xmO3pZffm7+683WaU1u+Xk5ZQVvNstVzrNAP1U0s+S4q2hmKQpPhzCz1PTcl6EenLjMrF1Q9/mnTlxm1iGAX1QdRD4nLjNr5xaXmSWp5mNc3tbGauuBgvLfin8sqHHVEu6e/+Kq9xfM0/qHJdx5KZ4GTi51W5t1isa9/dXVCrytjZnVhLuKZpaUoPZdRScuM2sXwPGqg8jnxGVm87nFZWZJ8XQIM0uSW1xmlhS3uMwW7xUF5Wv0x7nlb6N3+QfzNsQCrj2SX/7p/OK0OXGZWXK8VtHMkuQWl5klxRNQzSxJbnGZWVLc4jKz5HjJj5klKfUWl6RtwB8ARyPiouzcC4AvAOcDB4C3RMSPBhem2XxPFpT/TV5ZwTyt01oC87iW9VHnDmCi49x1wL0RsRa4Nzs2s1Fxss9PRQoTV0TcD/yw4/QGYHv283bgypLjMrOqzA3O9/OpyGLHuM6LiMMAEXFY0rklxmRmVRuBruKSSNosqSGpMbzd7c1s0eaW/PTz6YOkCUmPS9onqeuwkqS3SNojabekzxVdc7EtriOSVmatrZXA0V4VI2ISmITmyzIWeT8zG5YSB+cljQFbgcuBGWBa0lRE7Gmpsxb4S+CSiPhRPz24xba4pnj2FSpXAXcv8jpmVkfljXGtB/ZFxP6IOA7cSXOMvNU7ga1zMxMiomdDaE5h4pL0eeB7wG9KmpF0NXAjcLmk79PMpDf29Vcws/qba3GV81RxFe0zV2ayc61eCrxU0nclPSCpcxbDPIVdxYjY1KPosqLfNbMELayruEJSo+V4MhsemtPtHY+dQ0ZnAGuBS4HVwLclXRQR/9vrpp45b2btFrYf12zBC2FngNa3564GDnWp80BE/AL4L0mP00xk070uOvCnimaWoPLGuKaBtZIukPRcYCPNMfJWXwVeAyBpBc2u4/68i7rFZWbtSnyqGBEnJG0BdgJjwLaI2C3pBqAREVNZ2esk7cnu/OcR8T9511XE8GYojElx5tDuZnb6eRo4GdFtXKlv4y9SNN7fX129i10FXcWBcIvLzNp5Py4zS1LNl/w4cZlZO7/lx8ySk8B+XE5cZjafx7jMLClucZlZcpy4zCxJ7iqaWVL8VNHMkuOuopklyYnLzJLiJT9mliS3uMwsKR6cN7PkeHDezJLkMS4zS4pbXGaWJCcuM0uKp0OYWXICOF51EPmcuMxsPre4zCwpHpw3s+R4jMvMkuQWl5klxV1FM0tOAmsVlxVVkLRN0lFJj7Wcu17SQUkPZ5/XDzZMMxuqk31+KlKYuIA7gIku52+JiHXZZ0e5YZlZZeYG5/v5VKSwqxgR90s6f/ChmFlt1HyMq58WVy9bJD2SdSXPKS0iM6tWAi2uxSauW4GXAOuAw8BNvSpK2iypIakRi7yZmQ3R3JKffj4VWdRTxYg4MvezpNuAr+XUnQQmAcYk5y6zFNR8AuqiWlySVrYcvhF4rFddM0vM3DyuGj9VLGxxSfo8cCmwQtIM8GHgUknraP4VDwDXDDBGMxumUZiAGhGbupy+fQCxmFldjGJX0cxGWMldRUkTkh6XtE/SdTn13iQpJI0XXdNLfsysXYlLfiSNAVuBy4EZYFrSVETs6ah3NvAnwIP9XNctLjObr7wW13pgX0Tsj4jjwJ3Ahi71PgJ8DHi6n4s6cZlZu3InoK4Cnmw5nsnOPUPSxcCaiOg5raqTu4pmNl//TxVXSGq0HE9mczfnqMvvPDOfU9Iy4BbgHQsJz4nLzNotbDrEbETkDabPAGtajlcDh1qOzwYuAr4lCeDXgSlJb4iI1oTYxonLzOYrbzrENLBW0gXAQWAj8Na5woj4MbBi7ljSt4A/y0ta4MRlZp1KfKoYESckbQF2AmPAtojYLekGoBERU4u5riKGt3xwTIozh3Y3s9PP08DJiG7jSn0bH1M0lvdXV0+xq6CrOBBucZnZfKkv+TGz04xfT2ZmSXKLy8ySksBbfpy4zGyemje4nLjMrF0C23E5cZnZfDUfm3fiMrN2bnGZWZLc4jKzpJyi0jeP9cWJy8zmcYvLzJLiMS4zS5ITl5klJYGlik5cZtYugRU/TlxmNp+7imaWFA/Om1mSPMZlZklxi8vMkuPEZWbJSeGp4rKiCpLWSLpP0l5JuyVdm51/gaR7JH0/+/OcwYdrZsNwqs9PVQoTF3ACeF9EvAx4BfAuSRcC1wH3RsRa4N7s2MwSN9dV7OdTlcLEFRGHI+Kh7OengL3AKmADsD2rth24clBBmtlw1T1xLWiMS9L5wMXAg8B5EXEYmslN0rmlR2dmQzdSS34knQV8CXhPRPxE6u9luZI2A5sBlvR6XTMbmpF4qijpOTST1mcj4svZ6SOSVmatrZXA0W6/GxGTwCTAmBQlxGxmAzQqTxUF3A7sjYibW4qmgKuyn68C7i4/PDMbthQG5/tpcV0CvB14VNLD2bkPADcCd0m6GngCePNgQjSzYUt+jCsivkPv4anLyg3HzKrmmfNmliQnLjNLSgqD805cZtbGXUUzS1Lyg/NmdnpJocXVzyJrMzuNzC35KWt3CEkTkh6XtE/SvM0YJL1X0h5Jj0i6V9KLiq7pxGVm85Q1AVXSGLAVuAK4ENiU7S7T6t+B8Yj4beCLwMeKruvEZWZt5p4q9vPpw3pgX0Tsj4jjwJ00d5Z59n4R90XEz7LDB4DVRRd14jKzNiUv+VkFPNlyPJOd6+Vq4OtFF/XgvJnNs4DB+RWSGi3Hk9nGCnO6rbrputmCpLcB48Cri27qxGVmbRa4H9dsRIznlM8Aa1qOVwOHOitJei3wV8CrI+LnRTd14jKzeUqcDjENrJV0AXAQ2Ai8tbWCpIuBTwETEdF1e6xOTlxm1qbMHVAj4oSkLcBOYAzYFhG7Jd0ANCJiCvg74Czgn7MNSp+IiDfkXdeJy8zaBHC8zOtF7AB2dJz7UMvPr13oNZ24zGweL/kxs6SksOTHicvM2jhxmVmS3FU0s6R4I0EzS467imaWJCcuM0tKmRNQB8WJy8zmcYvLzJLiMS4zS46fKppZkjzGZWZJcVfRzJLkxGVmSfF0CDNLUt1bXIVv+ZG0RtJ9kvZK2i3p2uz89ZIOSno4+7x+8OGa2aCdotTXkw1EPy2uE8D7IuIhSWcDuyTdk5XdEhEfH1x4ZlaFure4ChNXRBwGDmc/PyVpL/nvRTOzhKUwxrWgF8JKOh+4GHgwO7VF0iOStkk6p8fvbJbUkNTo+jI1M6udEl8IOxB9Jy5JZwFfAt4TET8BbgVeAqyj2SK7qdvvRcRkRIxHxHi3N0OaWb2U/CbrgejrqaKk59BMWp+NiC8DRMSRlvLbgK8NJEIzG6oUlvz081RRwO3A3oi4ueX8ypZqbwQeKz88M6vCKLS4LgHeDjwq6eHs3AeATZLW0UzQB4BrBhKhmQ1VCoPz/TxV/A7QbXhqR5dzZjYCkp8OYWanl5FocZnZ6cctLjNLSgpPFZ24zKyN9+Mys+Q4cZlZkjw4b2ZJcYvLzJLkFpeZJSWA41UHUcCJy8zapDABdUH7cZnZ6aHMRdaSJiQ9LmmfpOu6lP+SpC9k5Q9m+/7lcuIyszZl7sclaQzYClwBXEhzc4YLO6pdDfwoIn4DuAX426LrOnGZ2Tyn+vz0YT2wLyL2R8Rx4E5gQ0edDcD27OcvApdl22n15MRlZm3mlvyU9JafVcCTLcczzH9nxTN1IuIE8GPgV/MuOtTB+VMw+zP4QcupFcDsMGNYgLrGVte4wLEtVpmxvWipFzgFO481Y+rHmZIaLceTETHZctyt5dT5+ol+6rQZauKKiF9rPZbUiIjxYcbQr7rGVte4wLEtVt1ii4iJEi83A6xpOV4NHOpRZ0bSGcDzgR/mXdRdRTMbpGlgraQLJD0X2AhMddSZAq7Kfn4T8M2IqE+Ly8xOLxFxQtIWYCcwBmyLiN2SbgAaETFF850Wn5G0j2ZLa2PRdatOXJPFVSpT19jqGhc4tsWqc2xLFhE76NjqPSI+1PLz08CbF3JNFbTIzMxqx2NcZpacShJX0RKAKkk6IOlRSQ93POatIpZtko5Keqzl3Ask3SPp+9mf59QotuslHcy+u4clvb6i2NZIuk/SXkm7JV2bna/0u8uJqxbfW0qG3lXMlgD8J3A5zceg08CmiNgz1EB6kHQAGI+Iyuf8SHoV8FPgnyLiouzcx4AfRsSNWdI/JyLeX5PYrgd+GhEfH3Y8HbGtBFZGxEOSzgZ2AVcC76DC7y4nrrdQg+8tJVW0uPpZAmBARNzP/PksrcsjttP8hz90PWKrhYg4HBEPZT8/BeylOTu70u8uJy5boCoSVz9LAKoUwDck7ZK0uepgujgvIg5D8z8CcG7F8XTaIumRrCtZSTe2VbbTwMXAg9Tou+uIC2r2vdVdFYlrwdP7h+ySiPgdmqvZ35V1iaw/twIvAdYBh4GbqgxG0lnAl4D3RMRPqoylVZe4avW9paCKxNXPEoDKRMSh7M+jwFdodm3r5Eg2VjI3ZnK04nieERFHIuJkRJwCbqPC707Sc2gmh89GxJez05V/d93iqtP3looqElc/SwAqIWl5NmiKpOXA64DH8n9r6FqXR1wF3F1hLG3mkkLmjVT03WVbotwO7I2Im1uKKv3uesVVl+8tJZVMQM0e9/49zy4B+OjQg+hC0otptrKguargc1XGJunzwKU0V+ofAT4MfBW4C3gh8ATw5ogY+iB5j9gupdndCeAAcM3cmNKQY3sl8G3gUZ7dNuoDNMeTKvvucuLaRA2+t5R45ryZJccz580sOU5cZpYcJy4zS44Tl5klx4nLzJLjxGVmyXHiMrPkOHGZWXL+H2e8qW7+7m/nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_images[7]\n",
    "transformed_image = transform_image(image,tx=18,ty=-15,zoom=2.0,rotation=45,shear=0.0)\n",
    "plot_image(transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of the FCN to Variations in the input\n",
    "We are now ready to systematically answer the question: how well does the FCN handle images that are slight (or not-so-slight) variations of the data it was trained on.   \n",
    "\n",
    "Here is what we will do: \n",
    "1.  Loop over every image in the test set\n",
    "2.  Choose a random +/- shift (in x and y) from a subset (0-4 pixels in increments of 1).\n",
    "3.  Randomly shift the image over that shift.\n",
    "4.  Store the transformed image in a list\n",
    "When we are done, we will run that list of images through our original FCN and note the performance, comparing it to the original performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift  0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 0.06523914116035448 0.9811\n",
      "   True:  0 \t 971 \t 1 \t 2 \t 0 \t 1 \t 1 \t 2 \t 1 \t 1 \t 0\n",
      "   True:  1 \t 0 \t 1127 \t 1 \t 1 \t 0 \t 1 \t 2 \t 1 \t 2 \t 0\n",
      "   True:  2 \t 4 \t 2 \t 1011 \t 3 \t 2 \t 0 \t 3 \t 3 \t 3 \t 1\n",
      "   True:  3 \t 0 \t 0 \t 3 \t 988 \t 0 \t 6 \t 0 \t 2 \t 8 \t 3\n",
      "   True:  4 \t 0 \t 0 \t 2 \t 1 \t 971 \t 0 \t 5 \t 0 \t 1 \t 2\n",
      "   True:  5 \t 1 \t 0 \t 0 \t 3 \t 1 \t 881 \t 1 \t 0 \t 3 \t 2\n",
      "   True:  6 \t 3 \t 3 \t 1 \t 1 \t 3 \t 5 \t 938 \t 0 \t 4 \t 0\n",
      "   True:  7 \t 0 \t 6 \t 9 \t 0 \t 4 \t 0 \t 0 \t 1001 \t 5 \t 3\n",
      "   True:  8 \t 2 \t 1 \t 2 \t 4 \t 5 \t 5 \t 1 \t 3 \t 947 \t 4\n",
      "   True:  9 \t 1 \t 4 \t 0 \t 3 \t 16 \t 4 \t 0 \t 2 \t 3 \t 976\n",
      "\n",
      "Shift  1\n",
      "10000/10000 [==============================] - 0s 18us/step\n",
      "   Results\n",
      "   Loss,acc 0.2531918545981869 0.9337\n",
      "   True:  0 \t 902 \t 0 \t 3 \t 5 \t 3 \t 25 \t 14 \t 6 \t 9 \t 13\n",
      "   True:  1 \t 0 \t 1054 \t 2 \t 0 \t 7 \t 4 \t 15 \t 27 \t 25 \t 1\n",
      "   True:  2 \t 6 \t 5 \t 970 \t 14 \t 7 \t 2 \t 12 \t 11 \t 4 \t 1\n",
      "   True:  3 \t 6 \t 2 \t 9 \t 947 \t 4 \t 17 \t 1 \t 10 \t 7 \t 7\n",
      "   True:  4 \t 2 \t 0 \t 2 \t 2 \t 942 \t 3 \t 9 \t 4 \t 4 \t 14\n",
      "   True:  5 \t 3 \t 0 \t 2 \t 15 \t 2 \t 850 \t 7 \t 1 \t 5 \t 7\n",
      "   True:  6 \t 5 \t 11 \t 6 \t 2 \t 5 \t 13 \t 907 \t 0 \t 8 \t 1\n",
      "   True:  7 \t 0 \t 8 \t 20 \t 5 \t 5 \t 1 \t 0 \t 969 \t 9 \t 11\n",
      "   True:  8 \t 2 \t 4 \t 5 \t 17 \t 6 \t 19 \t 5 \t 3 \t 905 \t 8\n",
      "   True:  9 \t 5 \t 4 \t 0 \t 14 \t 43 \t 8 \t 2 \t 25 \t 17 \t 891\n",
      "\n",
      "Shift  2\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 2.114796597766876 0.6221\n",
      "   True:  0 \t 353 \t 7 \t 127 \t 86 \t 12 \t 188 \t 76 \t 21 \t 55 \t 55\n",
      "   True:  1 \t 2 \t 467 \t 7 \t 20 \t 119 \t 94 \t 210 \t 140 \t 73 \t 3\n",
      "   True:  2 \t 6 \t 16 \t 739 \t 90 \t 33 \t 22 \t 88 \t 20 \t 17 \t 1\n",
      "   True:  3 \t 10 \t 24 \t 76 \t 782 \t 2 \t 43 \t 16 \t 27 \t 14 \t 16\n",
      "   True:  4 \t 3 \t 9 \t 28 \t 39 \t 657 \t 59 \t 29 \t 34 \t 77 \t 47\n",
      "   True:  5 \t 8 \t 11 \t 14 \t 62 \t 3 \t 673 \t 37 \t 9 \t 53 \t 22\n",
      "   True:  6 \t 12 \t 50 \t 56 \t 17 \t 26 \t 51 \t 718 \t 1 \t 26 \t 1\n",
      "   True:  7 \t 1 \t 9 \t 85 \t 24 \t 9 \t 17 \t 2 \t 765 \t 58 \t 58\n",
      "   True:  8 \t 9 \t 22 \t 33 \t 128 \t 6 \t 91 \t 36 \t 37 \t 534 \t 78\n",
      "   True:  9 \t 2 \t 5 \t 10 \t 37 \t 79 \t 45 \t 5 \t 164 \t 129 \t 533\n",
      "\n",
      "Shift  3\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 6.445082250213623 0.2581\n",
      "   True:  0 \t 14 \t 13 \t 272 \t 208 \t 12 \t 262 \t 94 \t 35 \t 36 \t 34\n",
      "   True:  1 \t 8 \t 218 \t 11 \t 85 \t 114 \t 161 \t 275 \t 219 \t 13 \t 31\n",
      "   True:  2 \t 1 \t 24 \t 390 \t 165 \t 22 \t 121 \t 248 \t 30 \t 20 \t 11\n",
      "   True:  3 \t 24 \t 43 \t 151 \t 380 \t 5 \t 71 \t 120 \t 58 \t 10 \t 148\n",
      "   True:  4 \t 2 \t 45 \t 77 \t 115 \t 195 \t 194 \t 59 \t 81 \t 162 \t 52\n",
      "   True:  5 \t 14 \t 25 \t 63 \t 108 \t 18 \t 387 \t 87 \t 25 \t 74 \t 91\n",
      "   True:  6 \t 19 \t 38 \t 243 \t 64 \t 48 \t 155 \t 309 \t 29 \t 39 \t 14\n",
      "   True:  7 \t 5 \t 10 \t 155 \t 130 \t 30 \t 84 \t 6 \t 377 \t 95 \t 136\n",
      "   True:  8 \t 5 \t 68 \t 53 \t 132 \t 4 \t 127 \t 150 \t 64 \t 136 \t 235\n",
      "   True:  9 \t 0 \t 16 \t 49 \t 235 \t 67 \t 167 \t 26 \t 85 \t 189 \t 175\n",
      "\n",
      "Shift  4\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 9.912869299316407 0.0932\n",
      "   True:  0 \t 0 \t 3 \t 287 \t 223 \t 8 \t 203 \t 109 \t 56 \t 7 \t 84\n",
      "   True:  1 \t 17 \t 81 \t 2 \t 28 \t 153 \t 160 \t 294 \t 282 \t 25 \t 93\n",
      "   True:  2 \t 2 \t 16 \t 124 \t 197 \t 17 \t 210 \t 358 \t 58 \t 19 \t 31\n",
      "   True:  3 \t 15 \t 35 \t 179 \t 91 \t 5 \t 106 \t 217 \t 77 \t 15 \t 270\n",
      "   True:  4 \t 12 \t 60 \t 160 \t 117 \t 37 \t 230 \t 68 \t 169 \t 101 \t 28\n",
      "   True:  5 \t 13 \t 18 \t 82 \t 69 \t 15 \t 238 \t 190 \t 55 \t 17 \t 195\n",
      "   True:  6 \t 23 \t 21 \t 222 \t 120 \t 33 \t 232 \t 147 \t 78 \t 54 \t 28\n",
      "   True:  7 \t 16 \t 21 \t 136 \t 262 \t 62 \t 166 \t 37 \t 109 \t 111 \t 108\n",
      "   True:  8 \t 4 \t 58 \t 27 \t 125 \t 8 \t 104 \t 224 \t 100 \t 43 \t 281\n",
      "   True:  9 \t 16 \t 43 \t 162 \t 250 \t 13 \t 265 \t 59 \t 38 \t 101 \t 62\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "for shift in [0,1,2,3,4]:\n",
    "    print()\n",
    "    print(\"Shift \",shift)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            tx = shift\n",
    "        else:\n",
    "            tx = -shift\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            ty = shift\n",
    "        else:\n",
    "            ty = -shift\n",
    "#        tx = random.uniform(-shift,shift)\n",
    "#        ty = random.uniform(-shift,shift)\n",
    "        trans_image = transform_image(img,tx=tx,ty=ty,zoom=1.0,rotation=0.0,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is bad.** As soon as we get 2 pixels out, the performance drops by almost 30%!   So the FCN is not stable at all against small variations in input.\n",
    "\n",
    "## Task 2: Test FCN Stability Further\n",
    "Using a similar strategy as above, try the following:\n",
    "1.  Rotations in the range: [0.0,20.0,40.0,60.0,80.0] (keep shifts=0)\n",
    "2.  Zooms in the range[1.0,1.25,1.5,1.75,2.0] (keep shifts and rotations=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rotation  0.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 0.06523914116035448 0.9811\n",
      "   True:  0 \t 971 \t 1 \t 2 \t 0 \t 1 \t 1 \t 2 \t 1 \t 1 \t 0\n",
      "   True:  1 \t 0 \t 1127 \t 1 \t 1 \t 0 \t 1 \t 2 \t 1 \t 2 \t 0\n",
      "   True:  2 \t 4 \t 2 \t 1011 \t 3 \t 2 \t 0 \t 3 \t 3 \t 3 \t 1\n",
      "   True:  3 \t 0 \t 0 \t 3 \t 988 \t 0 \t 6 \t 0 \t 2 \t 8 \t 3\n",
      "   True:  4 \t 0 \t 0 \t 2 \t 1 \t 971 \t 0 \t 5 \t 0 \t 1 \t 2\n",
      "   True:  5 \t 1 \t 0 \t 0 \t 3 \t 1 \t 881 \t 1 \t 0 \t 3 \t 2\n",
      "   True:  6 \t 3 \t 3 \t 1 \t 1 \t 3 \t 5 \t 938 \t 0 \t 4 \t 0\n",
      "   True:  7 \t 0 \t 6 \t 9 \t 0 \t 4 \t 0 \t 0 \t 1001 \t 5 \t 3\n",
      "   True:  8 \t 2 \t 1 \t 2 \t 4 \t 5 \t 5 \t 1 \t 3 \t 947 \t 4\n",
      "   True:  9 \t 1 \t 4 \t 0 \t 3 \t 16 \t 4 \t 0 \t 2 \t 3 \t 976\n",
      "\n",
      "Rotation  20.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 0.48035715011134744 0.8872\n",
      "   True:  0 \t 962 \t 0 \t 0 \t 1 \t 0 \t 8 \t 1 \t 2 \t 5 \t 1\n",
      "   True:  1 \t 1 \t 1052 \t 13 \t 6 \t 21 \t 7 \t 1 \t 1 \t 32 \t 1\n",
      "   True:  2 \t 13 \t 13 \t 878 \t 44 \t 24 \t 3 \t 7 \t 28 \t 18 \t 4\n",
      "   True:  3 \t 2 \t 1 \t 12 \t 917 \t 1 \t 31 \t 1 \t 9 \t 21 \t 15\n",
      "   True:  4 \t 1 \t 0 \t 18 \t 1 \t 873 \t 7 \t 14 \t 5 \t 31 \t 32\n",
      "   True:  5 \t 8 \t 3 \t 11 \t 5 \t 6 \t 818 \t 12 \t 2 \t 19 \t 8\n",
      "   True:  6 \t 8 \t 4 \t 0 \t 1 \t 31 \t 81 \t 828 \t 2 \t 3 \t 0\n",
      "   True:  7 \t 0 \t 11 \t 84 \t 9 \t 34 \t 2 \t 0 \t 819 \t 19 \t 50\n",
      "   True:  8 \t 13 \t 2 \t 19 \t 8 \t 14 \t 17 \t 8 \t 2 \t 887 \t 4\n",
      "   True:  9 \t 2 \t 4 \t 3 \t 11 \t 83 \t 10 \t 0 \t 15 \t 43 \t 838\n",
      "\n",
      "Rotation  40.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 3.351147952270508 0.489\n",
      "   True:  0 \t 920 \t 0 \t 4 \t 2 \t 1 \t 35 \t 2 \t 3 \t 6 \t 7\n",
      "   True:  1 \t 0 \t 588 \t 96 \t 3 \t 275 \t 56 \t 1 \t 3 \t 108 \t 5\n",
      "   True:  2 \t 47 \t 33 \t 278 \t 81 \t 153 \t 39 \t 22 \t 156 \t 179 \t 44\n",
      "   True:  3 \t 81 \t 9 \t 35 \t 549 \t 19 \t 102 \t 10 \t 30 \t 114 \t 61\n",
      "   True:  4 \t 15 \t 6 \t 329 \t 4 \t 315 \t 50 \t 53 \t 19 \t 154 \t 37\n",
      "   True:  5 \t 60 \t 3 \t 119 \t 4 \t 19 \t 479 \t 133 \t 10 \t 47 \t 18\n",
      "   True:  6 \t 28 \t 3 \t 4 \t 4 \t 75 \t 323 \t 501 \t 5 \t 12 \t 3\n",
      "   True:  7 \t 5 \t 26 \t 408 \t 29 \t 199 \t 10 \t 0 \t 192 \t 23 \t 136\n",
      "   True:  8 \t 65 \t 10 \t 120 \t 16 \t 44 \t 69 \t 34 \t 2 \t 594 \t 20\n",
      "   True:  9 \t 26 \t 7 \t 125 \t 9 \t 181 \t 18 \t 18 \t 29 \t 122 \t 474\n",
      "\n",
      "Rotation  60.0\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "   Results\n",
      "   Loss,acc 6.845488539886475 0.1931\n",
      "   True:  0 \t 836 \t 1 \t 13 \t 2 \t 3 \t 79 \t 6 \t 8 \t 20 \t 12\n",
      "   True:  1 \t 1 \t 115 \t 186 \t 6 \t 711 \t 18 \t 0 \t 2 \t 88 \t 8\n",
      "   True:  2 \t 64 \t 21 \t 52 \t 30 \t 240 \t 113 \t 12 \t 224 \t 226 \t 50\n",
      "   True:  3 \t 238 \t 4 \t 65 \t 104 \t 127 \t 128 \t 86 \t 29 \t 134 \t 95\n",
      "   True:  4 \t 11 \t 4 \t 547 \t 24 \t 112 \t 75 \t 87 \t 35 \t 86 \t 1\n",
      "   True:  5 \t 219 \t 3 \t 150 \t 5 \t 62 \t 122 \t 245 \t 31 \t 29 \t 26\n",
      "   True:  6 \t 49 \t 4 \t 38 \t 24 \t 147 \t 387 \t 257 \t 13 \t 27 \t 12\n",
      "   True:  7 \t 32 \t 6 \t 400 \t 18 \t 349 \t 36 \t 18 \t 25 \t 12 \t 132\n",
      "   True:  8 \t 147 \t 3 \t 268 \t 22 \t 111 \t 59 \t 119 \t 5 \t 190 \t 50\n",
      "   True:  9 \t 55 \t 5 \t 385 \t 19 \t 156 \t 20 \t 125 \t 50 \t 76 \t 118\n",
      "\n",
      "Rotation  80.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 8.185178791809083 0.1373\n",
      "   True:  0 \t 807 \t 1 \t 17 \t 5 \t 2 \t 71 \t 8 \t 7 \t 22 \t 40\n",
      "   True:  1 \t 0 \t 2 \t 93 \t 1 \t 963 \t 11 \t 3 \t 40 \t 21 \t 1\n",
      "   True:  2 \t 41 \t 4 \t 124 \t 13 \t 412 \t 138 \t 27 \t 101 \t 120 \t 52\n",
      "   True:  3 \t 194 \t 0 \t 65 \t 10 \t 265 \t 109 \t 207 \t 18 \t 85 \t 57\n",
      "   True:  4 \t 10 \t 9 \t 338 \t 34 \t 164 \t 133 \t 145 \t 90 \t 37 \t 22\n",
      "   True:  5 \t 217 \t 4 \t 50 \t 5 \t 174 \t 44 \t 283 \t 27 \t 23 \t 65\n",
      "   True:  6 \t 86 \t 19 \t 172 \t 102 \t 152 \t 228 \t 111 \t 23 \t 48 \t 17\n",
      "   True:  7 \t 49 \t 1 \t 170 \t 10 \t 499 \t 99 \t 100 \t 35 \t 18 \t 47\n",
      "   True:  8 \t 91 \t 0 \t 254 \t 8 \t 239 \t 56 \t 242 \t 12 \t 49 \t 23\n",
      "   True:  9 \t 38 \t 1 \t 320 \t 16 \t 189 \t 41 \t 323 \t 28 \t 26 \t 27\n"
     ]
    }
   ],
   "source": [
    "for rot in  [0.0,20.0,40.0,60.0,80.0]:\n",
    "    print()\n",
    "    print(\"Rotation \",rot)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            rotation = rot\n",
    "        else:\n",
    "            rotation = -rot\n",
    "\n",
    "        trans_image = transform_image(img,tx=0.0,ty=0.0,zoom=1.0,rotation=rotation,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zoom  1.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 3.8234260110855103 0.6779\n",
      "   True:  0 \t 942 \t 1 \t 3 \t 1 \t 2 \t 21 \t 5 \t 3 \t 0 \t 2\n",
      "   True:  1 \t 0 \t 1048 \t 1 \t 3 \t 2 \t 2 \t 2 \t 71 \t 4 \t 2\n",
      "   True:  2 \t 2 \t 14 \t 599 \t 11 \t 11 \t 44 \t 5 \t 44 \t 281 \t 21\n",
      "   True:  3 \t 0 \t 19 \t 28 \t 489 \t 3 \t 279 \t 11 \t 2 \t 166 \t 13\n",
      "   True:  4 \t 2 \t 70 \t 63 \t 42 \t 587 \t 11 \t 124 \t 6 \t 76 \t 1\n",
      "   True:  5 \t 2 \t 6 \t 10 \t 55 \t 1 \t 800 \t 5 \t 3 \t 3 \t 7\n",
      "   True:  6 \t 2 \t 3 \t 3 \t 24 \t 6 \t 33 \t 472 \t 31 \t 5 \t 379\n",
      "   True:  7 \t 0 \t 190 \t 218 \t 1 \t 6 \t 3 \t 103 \t 493 \t 13 \t 1\n",
      "   True:  8 \t 3 \t 6 \t 33 \t 53 \t 3 \t 3 \t 3 \t 3 \t 860 \t 7\n",
      "   True:  9 \t 1 \t 76 \t 13 \t 26 \t 9 \t 24 \t 321 \t 2 \t 48 \t 489\n",
      "\n",
      "Zoom  1.25\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 3.7300209980010988 0.5553\n",
      "   True:  0 \t 888 \t 1 \t 4 \t 2 \t 12 \t 7 \t 58 \t 6 \t 0 \t 2\n",
      "   True:  1 \t 0 \t 1066 \t 9 \t 0 \t 22 \t 0 \t 0 \t 36 \t 2 \t 0\n",
      "   True:  2 \t 6 \t 120 \t 505 \t 2 \t 79 \t 3 \t 15 \t 28 \t 274 \t 0\n",
      "   True:  3 \t 1 \t 163 \t 36 \t 422 \t 60 \t 95 \t 14 \t 13 \t 199 \t 7\n",
      "   True:  4 \t 0 \t 39 \t 25 \t 24 \t 660 \t 0 \t 226 \t 4 \t 4 \t 0\n",
      "   True:  5 \t 3 \t 37 \t 19 \t 104 \t 53 \t 606 \t 24 \t 20 \t 21 \t 5\n",
      "   True:  6 \t 1 \t 19 \t 0 \t 58 \t 480 \t 43 \t 310 \t 18 \t 2 \t 27\n",
      "   True:  7 \t 0 \t 297 \t 92 \t 7 \t 62 \t 2 \t 112 \t 447 \t 4 \t 5\n",
      "   True:  8 \t 4 \t 120 \t 55 \t 63 \t 72 \t 2 \t 18 \t 6 \t 621 \t 13\n",
      "   True:  9 \t 0 \t 127 \t 28 \t 53 \t 464 \t 13 \t 288 \t 2 \t 6 \t 28\n",
      "\n",
      "Zoom  1.5\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 4.31196838684082 0.345\n",
      "   True:  0 \t 468 \t 3 \t 11 \t 5 \t 164 \t 10 \t 266 \t 51 \t 0 \t 2\n",
      "   True:  1 \t 0 \t 1038 \t 7 \t 0 \t 81 \t 0 \t 0 \t 7 \t 2 \t 0\n",
      "   True:  2 \t 2 \t 212 \t 354 \t 3 \t 200 \t 1 \t 51 \t 35 \t 171 \t 3\n",
      "   True:  3 \t 0 \t 374 \t 37 \t 153 \t 273 \t 10 \t 25 \t 25 \t 76 \t 37\n",
      "   True:  4 \t 0 \t 18 \t 8 \t 19 \t 814 \t 0 \t 121 \t 0 \t 2 \t 0\n",
      "   True:  5 \t 0 \t 167 \t 27 \t 79 \t 319 \t 185 \t 38 \t 37 \t 20 \t 20\n",
      "   True:  6 \t 1 \t 21 \t 2 \t 14 \t 824 \t 10 \t 79 \t 3 \t 0 \t 4\n",
      "   True:  7 \t 0 \t 372 \t 65 \t 38 \t 220 \t 0 \t 60 \t 246 \t 4 \t 23\n",
      "   True:  8 \t 0 \t 276 \t 73 \t 31 \t 456 \t 1 \t 27 \t 2 \t 107 \t 1\n",
      "   True:  9 \t 0 \t 83 \t 17 \t 76 \t 703 \t 1 \t 122 \t 0 \t 1 \t 6\n",
      "\n",
      "Zoom  1.75\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 5.6314458045959475 0.2144\n",
      "   True:  0 \t 51 \t 5 \t 12 \t 2 \t 463 \t 5 \t 334 \t 108 \t 0 \t 0\n",
      "   True:  1 \t 0 \t 897 \t 4 \t 0 \t 231 \t 0 \t 0 \t 1 \t 1 \t 1\n",
      "   True:  2 \t 0 \t 236 \t 142 \t 5 \t 509 \t 0 \t 41 \t 44 \t 50 \t 5\n",
      "   True:  3 \t 0 \t 299 \t 11 \t 11 \t 539 \t 13 \t 6 \t 21 \t 3 \t 107\n",
      "   True:  4 \t 0 \t 13 \t 1 \t 10 \t 919 \t 0 \t 38 \t 1 \t 0 \t 0\n",
      "   True:  5 \t 0 \t 167 \t 12 \t 23 \t 592 \t 18 \t 24 \t 29 \t 3 \t 24\n",
      "   True:  6 \t 0 \t 27 \t 0 \t 5 \t 904 \t 3 \t 18 \t 0 \t 0 \t 1\n",
      "   True:  7 \t 0 \t 348 \t 12 \t 54 \t 469 \t 0 \t 27 \t 86 \t 3 \t 29\n",
      "   True:  8 \t 0 \t 214 \t 31 \t 14 \t 700 \t 0 \t 11 \t 2 \t 0 \t 2\n",
      "   True:  9 \t 0 \t 35 \t 1 \t 14 \t 933 \t 1 \t 23 \t 0 \t 0 \t 2\n",
      "\n",
      "Zoom  2.0\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "   Results\n",
      "   Loss,acc 6.826110978698731 0.1723\n",
      "   True:  0 \t 1 \t 3 \t 0 \t 2 \t 741 \t 2 \t 188 \t 43 \t 0 \t 0\n",
      "   True:  1 \t 0 \t 727 \t 0 \t 0 \t 406 \t 0 \t 0 \t 1 \t 1 \t 0\n",
      "   True:  2 \t 0 \t 189 \t 9 \t 1 \t 787 \t 1 \t 11 \t 21 \t 10 \t 3\n",
      "   True:  3 \t 0 \t 213 \t 0 \t 2 \t 718 \t 5 \t 0 \t 2 \t 1 \t 69\n",
      "   True:  4 \t 0 \t 8 \t 0 \t 12 \t 960 \t 0 \t 2 \t 0 \t 0 \t 0\n",
      "   True:  5 \t 0 \t 122 \t 1 \t 2 \t 722 \t 6 \t 4 \t 6 \t 1 \t 28\n",
      "   True:  6 \t 0 \t 26 \t 0 \t 4 \t 923 \t 0 \t 3 \t 1 \t 0 \t 1\n",
      "   True:  7 \t 0 \t 288 \t 2 \t 16 \t 685 \t 0 \t 6 \t 14 \t 2 \t 15\n",
      "   True:  8 \t 0 \t 133 \t 4 \t 0 \t 833 \t 0 \t 0 \t 2 \t 0 \t 2\n",
      "   True:  9 \t 0 \t 31 \t 0 \t 1 \t 975 \t 0 \t 1 \t 0 \t 0 \t 1\n"
     ]
    }
   ],
   "source": [
    "for zoom in [1.0,1.25,1.5,1.75,2.0]:\n",
    "    print()\n",
    "    print(\"Zoom \",zoom)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            Zoom = zoom\n",
    "        else:\n",
    "            Zoom = -zoom\n",
    "\n",
    "        trans_image = transform_image(img,tx=0.0,ty=0.0,zoom=Zoom,rotation=0.0,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcomings of FCNs\n",
    "We see that standard, fully-connected neural networks, although powerful, have some clear shortcomings when applied to image classification:\n",
    "1.  They do not scale well.  Reasonable-sized images would require an enormous number of parameters.   This in turn would require a corresponding increase in the number of training samples in order to determine the parameters accurately.\n",
    "2.  They are dependent on the specific pixel relationships within the image.   Performance degrades substantially as soon as there is a minor devation from these relationships.\n",
    "\n",
    "Both of these issues are related: the FCN does not take advantage of the fact that - generally - in image classification, the images tend to be built from underlying common features.   In the case of MNIST images, these are the curves and lines and corners which make up the individual digits.   Convnets attempt to take advantage of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convnet\n",
    "Before explaining how convnets work, lets try to build a simple network to classify MNIST images.\n",
    "\n",
    "For comparison, we first show the code we use to build and train an FCN, followed by similar code to build and train a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3309 - acc: 0.9035 - val_loss: 0.2153 - val_acc: 0.9369\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1790 - acc: 0.9483 - val_loss: 0.1500 - val_acc: 0.9564\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1237 - acc: 0.9635 - val_loss: 0.1135 - val_acc: 0.9674\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0899 - acc: 0.9740 - val_loss: 0.0991 - val_acc: 0.9701\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0695 - acc: 0.9801 - val_loss: 0.0853 - val_acc: 0.9737\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0546 - acc: 0.9841 - val_loss: 0.0784 - val_acc: 0.9745\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0428 - acc: 0.9880 - val_loss: 0.0810 - val_acc: 0.9742\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0333 - acc: 0.9910 - val_loss: 0.0715 - val_acc: 0.9775\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0264 - acc: 0.9930 - val_loss: 0.0668 - val_acc: 0.9805\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0204 - acc: 0.9950 - val_loss: 0.0660 - val_acc: 0.9793\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0158 - acc: 0.9966 - val_loss: 0.0668 - val_acc: 0.9789\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0120 - acc: 0.9978 - val_loss: 0.0661 - val_acc: 0.9794\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0678 - val_acc: 0.9793\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0661 - val_acc: 0.9807\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0656 - val_acc: 0.9817\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#\n",
    "# Make sure the shape of the input is correct\n",
    "train_images = train_images.reshape((train_images.shape[0],28*28))\n",
    "test_images = test_images.reshape((test_images.shape[0],28*28))\n",
    "\n",
    "fcn_network = models.Sequential()\n",
    "#\n",
    "# Hidden\n",
    "fcn_network.add(layers.Dense(400,activation='tanh',input_shape=(28*28,)))\n",
    "#\n",
    "# Output\n",
    "fcn_network.add(layers.Dense(10,activation='softmax'))\n",
    "#\n",
    "# Compile\n",
    "fcn_network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# \n",
    "# Fit/save/print summary\n",
    "history = fcn_network.fit(train_images,train_labels_cat,epochs=15,batch_size=128,validation_data=(test_images,test_labels_cat))\n",
    "fcn_network.save('fully_trained_model_fcn.h5')\n",
    "print(fcn_network.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.3722 - acc: 0.8874 - val_loss: 0.1281 - val_acc: 0.9600\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.0957 - acc: 0.9704 - val_loss: 0.0630 - val_acc: 0.9794\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0599 - acc: 0.9816 - val_loss: 0.0558 - val_acc: 0.9816\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.0438 - acc: 0.9864 - val_loss: 0.0510 - val_acc: 0.9830\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.0350 - acc: 0.9891 - val_loss: 0.0288 - val_acc: 0.9903\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 25)          18775     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                25664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 45,869\n",
      "Trainable params: 45,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "#\n",
    "# Make sure the shape of the input is correct (the last \",1\" is the number of \"channels\"=1 for grayscale)\n",
    "train_images = train_images.reshape((train_images.shape[0],28,28,1))\n",
    "test_images = test_images.reshape((test_images.shape[0],28,28,1))\n",
    "#\n",
    "cnn_network = models.Sequential()\n",
    "#\n",
    "# First convolutional layer\n",
    "cnn_network.add(layers.Conv2D(30,(5,5),activation='relu',input_shape=(28,28,1)))\n",
    "# Pool\n",
    "cnn_network.add(layers.MaxPooling2D((2,2)))\n",
    "#\n",
    "# Second convolutional layer\n",
    "cnn_network.add(layers.Conv2D(25,(5,5),activation='relu'))\n",
    "# Pool\n",
    "cnn_network.add(layers.MaxPooling2D((2,2)))\n",
    "#\n",
    "# Connect to a dense output layer - just like an FCN\n",
    "cnn_network.add(layers.Flatten())\n",
    "cnn_network.add(layers.Dense(64,activation='relu'))\n",
    "cnn_network.add(layers.Dense(10,activation='softmax'))\n",
    "#\n",
    "# Compile\n",
    "cnn_network.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#\n",
    "# Fit/save/print summary\n",
    "history = cnn_network.fit(train_images,train_labels_cat,epochs=5,batch_size=256,validation_data=(test_images,test_labels_cat))\n",
    "cnn_network.save('fully_trained_model_cnn.h5')\n",
    "print(cnn_network.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 143us/step\n",
      "Test sample loss:  0.02883571804226376 ; Test sample accuracy:  0.9903\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get the overall performance for the test sample\n",
    "test_loss, test_acc = cnn_network.evaluate(test_images,test_labels_cat)\n",
    "print(\"Test sample loss: \",test_loss, \"; Test sample accuracy: \",test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of CNN and FCN\n",
    "There are a couple of things to notice when comparing the output from the two code blocks above:\n",
    "1.  The performance of the CNN is better than the FCN after 5 epochs.  A careful examination of the training set accuracies reveals that the CNN is still undertrained (and so can perform better if we increase the number of epochs).\n",
    "2.  The number of parameters needed to specify the CNN is 40.3k, about 7 times smaller than the FCN!\n",
    "3.  The training time per step is much longer (about 10x) for the CNN than it is for the FCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Test CNN Stability \n",
    "What we don't know yet, is how stable the CNN is to variations in the input images.\n",
    "Using a similar strategy as we used above for the FCN, calaculate the performance under the following variations:\n",
    "1.  Shifts in the range [0,1,2,3,4]\n",
    "2.  Rotations in the range: [0.0,20.0,40.0,60.0,80.0] (keep shifts=0)\n",
    "3.  Zooms in the range[1.0,1.25,1.5,1.75,2.0] (keep shifts and rotations=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift  0\n",
      "10000/10000 [==============================] - 1s 149us/step\n",
      "   Results\n",
      "   Loss,acc 0.02883571804226376 0.9903\n",
      "   True:  0 \t 971 \t 0 \t 0 \t 0 \t 0 \t 1 \t 0 \t 2 \t 3 \t 3\n",
      "   True:  1 \t 0 \t 1132 \t 0 \t 0 \t 0 \t 0 \t 1 \t 2 \t 0 \t 0\n",
      "   True:  2 \t 1 \t 0 \t 1019 \t 0 \t 2 \t 0 \t 0 \t 7 \t 3 \t 0\n",
      "   True:  3 \t 0 \t 0 \t 0 \t 1003 \t 0 \t 2 \t 0 \t 4 \t 1 \t 0\n",
      "   True:  4 \t 0 \t 0 \t 0 \t 0 \t 975 \t 0 \t 0 \t 0 \t 1 \t 6\n",
      "   True:  5 \t 2 \t 0 \t 0 \t 10 \t 0 \t 875 \t 1 \t 1 \t 1 \t 2\n",
      "   True:  6 \t 2 \t 2 \t 0 \t 1 \t 3 \t 2 \t 947 \t 0 \t 1 \t 0\n",
      "   True:  7 \t 0 \t 1 \t 3 \t 1 \t 0 \t 0 \t 0 \t 1019 \t 1 \t 3\n",
      "   True:  8 \t 1 \t 0 \t 2 \t 2 \t 0 \t 0 \t 1 \t 1 \t 962 \t 5\n",
      "   True:  9 \t 0 \t 1 \t 0 \t 0 \t 4 \t 0 \t 0 \t 3 \t 1 \t 1000\n",
      "\n",
      "Shift  1\n",
      "10000/10000 [==============================] - 1s 144us/step\n",
      "   Results\n",
      "   Loss,acc 0.08062225584890693 0.9754\n",
      "   True:  0 \t 931 \t 0 \t 1 \t 4 \t 3 \t 1 \t 9 \t 3 \t 5 \t 23\n",
      "   True:  1 \t 0 \t 1127 \t 0 \t 0 \t 2 \t 1 \t 1 \t 3 \t 1 \t 0\n",
      "   True:  2 \t 2 \t 1 \t 1011 \t 4 \t 3 \t 0 \t 0 \t 9 \t 2 \t 0\n",
      "   True:  3 \t 1 \t 0 \t 4 \t 996 \t 0 \t 2 \t 0 \t 3 \t 2 \t 2\n",
      "   True:  4 \t 0 \t 0 \t 1 \t 0 \t 967 \t 0 \t 1 \t 1 \t 2 \t 10\n",
      "   True:  5 \t 1 \t 1 \t 0 \t 16 \t 0 \t 861 \t 3 \t 2 \t 1 \t 7\n",
      "   True:  6 \t 1 \t 3 \t 1 \t 1 \t 3 \t 9 \t 935 \t 0 \t 3 \t 2\n",
      "   True:  7 \t 0 \t 5 \t 10 \t 1 \t 0 \t 1 \t 0 \t 1005 \t 4 \t 2\n",
      "   True:  8 \t 5 \t 0 \t 4 \t 0 \t 3 \t 4 \t 6 \t 2 \t 940 \t 10\n",
      "   True:  9 \t 3 \t 1 \t 2 \t 3 \t 2 \t 4 \t 0 \t 5 \t 8 \t 981\n",
      "\n",
      "Shift  2\n",
      "10000/10000 [==============================] - 1s 142us/step\n",
      "   Results\n",
      "   Loss,acc 0.5029811957001686 0.8532\n",
      "   True:  0 \t 603 \t 9 \t 15 \t 18 \t 16 \t 11 \t 70 \t 39 \t 18 \t 181\n",
      "   True:  1 \t 0 \t 1062 \t 2 \t 1 \t 30 \t 3 \t 3 \t 28 \t 3 \t 3\n",
      "   True:  2 \t 4 \t 6 \t 920 \t 15 \t 20 \t 2 \t 5 \t 48 \t 7 \t 5\n",
      "   True:  3 \t 9 \t 0 \t 23 \t 916 \t 2 \t 27 \t 0 \t 22 \t 8 \t 3\n",
      "   True:  4 \t 7 \t 10 \t 21 \t 6 \t 898 \t 0 \t 10 \t 11 \t 7 \t 12\n",
      "   True:  5 \t 5 \t 3 \t 4 \t 38 \t 1 \t 779 \t 10 \t 0 \t 18 \t 34\n",
      "   True:  6 \t 12 \t 16 \t 5 \t 0 \t 60 \t 18 \t 790 \t 0 \t 16 \t 41\n",
      "   True:  7 \t 1 \t 17 \t 18 \t 7 \t 9 \t 2 \t 0 \t 966 \t 5 \t 3\n",
      "   True:  8 \t 11 \t 5 \t 13 \t 23 \t 13 \t 30 \t 18 \t 22 \t 800 \t 39\n",
      "   True:  9 \t 11 \t 8 \t 4 \t 39 \t 26 \t 19 \t 15 \t 31 \t 58 \t 798\n",
      "\n",
      "Shift  3\n",
      "10000/10000 [==============================] - 1s 146us/step\n",
      "   Results\n",
      "   Loss,acc 2.0946692733764647 0.5282\n",
      "   True:  0 \t 180 \t 100 \t 58 \t 64 \t 35 \t 40 \t 181 \t 100 \t 50 \t 172\n",
      "   True:  1 \t 0 \t 567 \t 4 \t 2 \t 333 \t 5 \t 9 \t 192 \t 15 \t 8\n",
      "   True:  2 \t 5 \t 10 \t 686 \t 37 \t 102 \t 20 \t 16 \t 135 \t 10 \t 11\n",
      "   True:  3 \t 36 \t 3 \t 139 \t 602 \t 12 \t 73 \t 12 \t 73 \t 37 \t 23\n",
      "   True:  4 \t 14 \t 46 \t 78 \t 14 \t 691 \t 9 \t 34 \t 64 \t 21 \t 11\n",
      "   True:  5 \t 21 \t 3 \t 36 \t 62 \t 5 \t 605 \t 33 \t 7 \t 56 \t 64\n",
      "   True:  6 \t 18 \t 100 \t 32 \t 2 \t 179 \t 33 \t 429 \t 0 \t 28 \t 137\n",
      "   True:  7 \t 2 \t 53 \t 49 \t 25 \t 22 \t 25 \t 4 \t 815 \t 29 \t 4\n",
      "   True:  8 \t 11 \t 38 \t 39 \t 89 \t 34 \t 125 \t 91 \t 67 \t 410 \t 70\n",
      "   True:  9 \t 19 \t 24 \t 15 \t 87 \t 102 \t 31 \t 127 \t 174 \t 133 \t 297\n",
      "\n",
      "Shift  4\n",
      "10000/10000 [==============================] - 1s 142us/step\n",
      "   Results\n",
      "   Loss,acc 4.611449179077148 0.2502\n",
      "   True:  0 \t 22 \t 181 \t 112 \t 66 \t 123 \t 72 \t 148 \t 140 \t 70 \t 46\n",
      "   True:  1 \t 4 \t 330 \t 1 \t 3 \t 446 \t 3 \t 33 \t 270 \t 26 \t 19\n",
      "   True:  2 \t 9 \t 32 \t 302 \t 58 \t 239 \t 57 \t 62 \t 209 \t 51 \t 13\n",
      "   True:  3 \t 43 \t 4 \t 303 \t 193 \t 16 \t 105 \t 21 \t 208 \t 67 \t 50\n",
      "   True:  4 \t 36 \t 143 \t 167 \t 5 \t 328 \t 26 \t 62 \t 191 \t 19 \t 5\n",
      "   True:  5 \t 24 \t 13 \t 146 \t 55 \t 26 \t 386 \t 89 \t 53 \t 45 \t 55\n",
      "   True:  6 \t 29 \t 172 \t 77 \t 5 \t 237 \t 54 \t 170 \t 4 \t 36 \t 174\n",
      "   True:  7 \t 0 \t 88 \t 68 \t 77 \t 64 \t 87 \t 17 \t 582 \t 45 \t 0\n",
      "   True:  8 \t 15 \t 62 \t 76 \t 149 \t 113 \t 122 \t 95 \t 124 \t 140 \t 78\n",
      "   True:  9 \t 34 \t 52 \t 35 \t 35 \t 137 \t 36 \t 202 \t 360 \t 69 \t 49\n"
     ]
    }
   ],
   "source": [
    "trained_network = load_model('fully_trained_model_cnn.h5')\n",
    "\n",
    "for shift in [0,1,2,3,4]:\n",
    "    print()\n",
    "    print(\"Shift \",shift)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            tx = shift\n",
    "        else:\n",
    "            tx = -shift\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            ty = shift\n",
    "        else:\n",
    "            ty = -shift\n",
    "#        tx = random.uniform(-shift,shift)\n",
    "#        ty = random.uniform(-shift,shift)\n",
    "        trans_image = transform_image(img,tx=tx,ty=ty,zoom=1.0,rotation=0.0,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    #npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rotation  0.0\n",
      "10000/10000 [==============================] - 1s 148us/step\n",
      "   Results\n",
      "   Loss,acc 0.02883571804226376 0.9903\n",
      "   True:  0 \t 971 \t 0 \t 0 \t 0 \t 0 \t 1 \t 0 \t 2 \t 3 \t 3\n",
      "   True:  1 \t 0 \t 1132 \t 0 \t 0 \t 0 \t 0 \t 1 \t 2 \t 0 \t 0\n",
      "   True:  2 \t 1 \t 0 \t 1019 \t 0 \t 2 \t 0 \t 0 \t 7 \t 3 \t 0\n",
      "   True:  3 \t 0 \t 0 \t 0 \t 1003 \t 0 \t 2 \t 0 \t 4 \t 1 \t 0\n",
      "   True:  4 \t 0 \t 0 \t 0 \t 0 \t 975 \t 0 \t 0 \t 0 \t 1 \t 6\n",
      "   True:  5 \t 2 \t 0 \t 0 \t 10 \t 0 \t 875 \t 1 \t 1 \t 1 \t 2\n",
      "   True:  6 \t 2 \t 2 \t 0 \t 1 \t 3 \t 2 \t 947 \t 0 \t 1 \t 0\n",
      "   True:  7 \t 0 \t 1 \t 3 \t 1 \t 0 \t 0 \t 0 \t 1019 \t 1 \t 3\n",
      "   True:  8 \t 1 \t 0 \t 2 \t 2 \t 0 \t 0 \t 1 \t 1 \t 962 \t 5\n",
      "   True:  9 \t 0 \t 1 \t 0 \t 0 \t 4 \t 0 \t 0 \t 3 \t 1 \t 1000\n",
      "\n",
      "Rotation  20.0\n",
      "10000/10000 [==============================] - 1s 143us/step\n",
      "   Results\n",
      "   Loss,acc 0.17747585138343275 0.941\n",
      "   True:  0 \t 964 \t 0 \t 4 \t 0 \t 2 \t 3 \t 0 \t 3 \t 1 \t 3\n",
      "   True:  1 \t 0 \t 1110 \t 1 \t 3 \t 3 \t 5 \t 0 \t 3 \t 10 \t 0\n",
      "   True:  2 \t 4 \t 6 \t 943 \t 3 \t 5 \t 2 \t 1 \t 52 \t 13 \t 3\n",
      "   True:  3 \t 0 \t 0 \t 4 \t 974 \t 0 \t 6 \t 0 \t 12 \t 9 \t 5\n",
      "   True:  4 \t 1 \t 0 \t 10 \t 0 \t 908 \t 0 \t 2 \t 5 \t 36 \t 20\n",
      "   True:  5 \t 1 \t 1 \t 0 \t 17 \t 3 \t 846 \t 8 \t 2 \t 9 \t 5\n",
      "   True:  6 \t 5 \t 2 \t 0 \t 1 \t 9 \t 32 \t 903 \t 0 \t 6 \t 0\n",
      "   True:  7 \t 0 \t 13 \t 55 \t 3 \t 9 \t 0 \t 0 \t 894 \t 14 \t 40\n",
      "   True:  8 \t 5 \t 0 \t 5 \t 4 \t 14 \t 8 \t 6 \t 2 \t 920 \t 10\n",
      "   True:  9 \t 3 \t 2 \t 1 \t 0 \t 4 \t 8 \t 1 \t 6 \t 36 \t 948\n",
      "\n",
      "Rotation  40.0\n",
      "10000/10000 [==============================] - 1s 142us/step\n",
      "   Results\n",
      "   Loss,acc 1.6252131603240967 0.6151\n",
      "   True:  0 \t 926 \t 0 \t 3 \t 0 \t 0 \t 19 \t 0 \t 7 \t 10 \t 15\n",
      "   True:  1 \t 0 \t 736 \t 81 \t 2 \t 42 \t 138 \t 1 \t 4 \t 131 \t 0\n",
      "   True:  2 \t 27 \t 20 \t 515 \t 4 \t 42 \t 7 \t 3 \t 260 \t 143 \t 11\n",
      "   True:  3 \t 26 \t 0 \t 20 \t 576 \t 8 \t 118 \t 6 \t 68 \t 103 \t 85\n",
      "   True:  4 \t 23 \t 7 \t 181 \t 12 \t 350 \t 70 \t 9 \t 20 \t 278 \t 32\n",
      "   True:  5 \t 18 \t 1 \t 1 \t 22 \t 27 \t 675 \t 93 \t 5 \t 24 \t 26\n",
      "   True:  6 \t 25 \t 1 \t 0 \t 1 \t 23 \t 231 \t 659 \t 1 \t 17 \t 0\n",
      "   True:  7 \t 3 \t 33 \t 329 \t 7 \t 149 \t 4 \t 2 \t 335 \t 25 \t 141\n",
      "   True:  8 \t 34 \t 0 \t 58 \t 1 \t 62 \t 76 \t 24 \t 4 \t 684 \t 31\n",
      "   True:  9 \t 22 \t 2 \t 21 \t 7 \t 26 \t 116 \t 11 \t 8 \t 101 \t 695\n",
      "\n",
      "Rotation  60.0\n",
      "10000/10000 [==============================] - 1s 145us/step\n",
      "   Results\n",
      "   Loss,acc 4.4834316520690916 0.2547\n",
      "   True:  0 \t 851 \t 0 \t 0 \t 0 \t 0 \t 43 \t 2 \t 15 \t 30 \t 39\n",
      "   True:  1 \t 0 \t 196 \t 218 \t 0 \t 292 \t 223 \t 1 \t 20 \t 185 \t 0\n",
      "   True:  2 \t 50 \t 10 \t 153 \t 0 \t 99 \t 10 \t 6 \t 442 \t 245 \t 17\n",
      "   True:  3 \t 211 \t 0 \t 18 \t 71 \t 58 \t 188 \t 76 \t 168 \t 156 \t 64\n",
      "   True:  4 \t 5 \t 3 \t 230 \t 65 \t 52 \t 300 \t 15 \t 53 \t 256 \t 3\n",
      "   True:  5 \t 166 \t 1 \t 0 \t 11 \t 44 \t 329 \t 274 \t 6 \t 15 \t 46\n",
      "   True:  6 \t 63 \t 1 \t 1 \t 13 \t 53 \t 396 \t 345 \t 2 \t 78 \t 6\n",
      "   True:  7 \t 30 \t 10 \t 447 \t 17 \t 322 \t 46 \t 15 \t 61 \t 15 \t 65\n",
      "   True:  8 \t 76 \t 0 \t 122 \t 2 \t 166 \t 140 \t 141 \t 4 \t 291 \t 32\n",
      "   True:  9 \t 87 \t 0 \t 97 \t 7 \t 41 \t 293 \t 134 \t 5 \t 147 \t 198\n",
      "\n",
      "Rotation  80.0\n",
      "10000/10000 [==============================] - 1s 144us/step\n",
      "   Results\n",
      "   Loss,acc 6.010875065612793 0.1764\n",
      "   True:  0 \t 823 \t 0 \t 0 \t 3 \t 0 \t 65 \t 4 \t 3 \t 44 \t 38\n",
      "   True:  1 \t 0 \t 8 \t 381 \t 0 \t 454 \t 127 \t 5 \t 137 \t 23 \t 0\n",
      "   True:  2 \t 48 \t 4 \t 204 \t 2 \t 266 \t 7 \t 23 \t 295 \t 151 \t 32\n",
      "   True:  3 \t 218 \t 2 \t 7 \t 2 \t 140 \t 129 \t 287 \t 116 \t 97 \t 12\n",
      "   True:  4 \t 4 \t 3 \t 175 \t 104 \t 87 \t 397 \t 14 \t 100 \t 98 \t 0\n",
      "   True:  5 \t 186 \t 1 \t 2 \t 0 \t 89 \t 176 \t 346 \t 7 \t 6 \t 79\n",
      "   True:  6 \t 99 \t 1 \t 1 \t 47 \t 48 \t 400 \t 197 \t 4 \t 128 \t 33\n",
      "   True:  7 \t 43 \t 5 \t 199 \t 2 \t 407 \t 123 \t 121 \t 74 \t 39 \t 15\n",
      "   True:  8 \t 59 \t 0 \t 123 \t 0 \t 119 \t 81 \t 356 \t 26 \t 165 \t 45\n",
      "   True:  9 \t 70 \t 0 \t 110 \t 8 \t 135 \t 261 \t 286 \t 3 \t 108 \t 28\n"
     ]
    }
   ],
   "source": [
    "trained_network = load_model('fully_trained_model_cnn.h5')\n",
    "\n",
    "for rot in  [0.0,20.0,40.0,60.0,80.0]:\n",
    "    print()\n",
    "    print(\"Rotation \",rot)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            rotation = rot\n",
    "        else:\n",
    "            rotation = -rot\n",
    "\n",
    "        trans_image = transform_image(img,tx=0.0,ty=0.0,zoom=1.0,rotation=rotation,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    #npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zoom  1.0\n",
      "10000/10000 [==============================] - 1s 148us/step\n",
      "   Results\n",
      "   Loss,acc 3.218460690689087 0.7173\n",
      "   True:  0 \t 950 \t 0 \t 1 \t 0 \t 1 \t 0 \t 0 \t 13 \t 3 \t 12\n",
      "   True:  1 \t 0 \t 1114 \t 0 \t 1 \t 2 \t 3 \t 0 \t 12 \t 1 \t 2\n",
      "   True:  2 \t 6 \t 6 \t 607 \t 0 \t 6 \t 9 \t 5 \t 103 \t 290 \t 0\n",
      "   True:  3 \t 1 \t 1 \t 10 \t 501 \t 0 \t 170 \t 20 \t 3 \t 287 \t 17\n",
      "   True:  4 \t 1 \t 26 \t 8 \t 14 \t 755 \t 16 \t 86 \t 45 \t 30 \t 1\n",
      "   True:  5 \t 2 \t 2 \t 2 \t 40 \t 3 \t 805 \t 1 \t 0 \t 8 \t 29\n",
      "   True:  6 \t 6 \t 1 \t 0 \t 6 \t 2 \t 9 \t 507 \t 37 \t 0 \t 390\n",
      "   True:  7 \t 2 \t 223 \t 130 \t 1 \t 26 \t 0 \t 133 \t 498 \t 14 \t 1\n",
      "   True:  8 \t 0 \t 1 \t 9 \t 24 \t 0 \t 3 \t 2 \t 0 \t 928 \t 7\n",
      "   True:  9 \t 4 \t 11 \t 1 \t 23 \t 5 \t 13 \t 402 \t 2 \t 40 \t 508\n",
      "\n",
      "Zoom  1.25\n",
      "10000/10000 [==============================] - 1s 147us/step\n",
      "   Results\n",
      "   Loss,acc 2.6526668668746947 0.695\n",
      "   True:  0 \t 921 \t 0 \t 0 \t 0 \t 4 \t 5 \t 30 \t 3 \t 1 \t 16\n",
      "   True:  1 \t 0 \t 1119 \t 2 \t 0 \t 2 \t 0 \t 0 \t 8 \t 2 \t 2\n",
      "   True:  2 \t 6 \t 8 \t 641 \t 3 \t 2 \t 7 \t 25 \t 45 \t 295 \t 0\n",
      "   True:  3 \t 0 \t 6 \t 11 \t 483 \t 0 \t 141 \t 72 \t 4 \t 286 \t 7\n",
      "   True:  4 \t 1 \t 14 \t 4 \t 12 \t 633 \t 23 \t 228 \t 9 \t 51 \t 7\n",
      "   True:  5 \t 0 \t 2 \t 1 \t 69 \t 0 \t 787 \t 9 \t 1 \t 7 \t 16\n",
      "   True:  6 \t 1 \t 3 \t 1 \t 30 \t 3 \t 35 \t 460 \t 67 \t 1 \t 357\n",
      "   True:  7 \t 0 \t 208 \t 110 \t 1 \t 31 \t 1 \t 153 \t 512 \t 4 \t 8\n",
      "   True:  8 \t 2 \t 8 \t 15 \t 27 \t 1 \t 1 \t 5 \t 1 \t 901 \t 13\n",
      "   True:  9 \t 0 \t 21 \t 2 \t 22 \t 2 \t 7 \t 444 \t 1 \t 17 \t 493\n",
      "\n",
      "Zoom  1.5\n",
      "10000/10000 [==============================] - 1s 141us/step\n",
      "   Results\n",
      "   Loss,acc 2.245059085845947 0.622\n",
      "   True:  0 \t 688 \t 0 \t 0 \t 1 \t 9 \t 20 \t 204 \t 3 \t 2 \t 53\n",
      "   True:  1 \t 0 \t 1117 \t 1 \t 2 \t 0 \t 0 \t 0 \t 5 \t 5 \t 5\n",
      "   True:  2 \t 3 \t 9 \t 604 \t 7 \t 6 \t 1 \t 109 \t 58 \t 233 \t 2\n",
      "   True:  3 \t 0 \t 5 \t 16 \t 472 \t 0 \t 101 \t 246 \t 5 \t 133 \t 32\n",
      "   True:  4 \t 0 \t 17 \t 4 \t 3 \t 510 \t 29 \t 380 \t 3 \t 18 \t 18\n",
      "   True:  5 \t 1 \t 2 \t 2 \t 84 \t 3 \t 755 \t 38 \t 0 \t 4 \t 3\n",
      "   True:  6 \t 1 \t 4 \t 1 \t 116 \t 52 \t 123 \t 424 \t 37 \t 1 \t 199\n",
      "   True:  7 \t 0 \t 182 \t 84 \t 3 \t 69 \t 0 \t 201 \t 459 \t 7 \t 23\n",
      "   True:  8 \t 1 \t 43 \t 44 \t 46 \t 1 \t 13 \t 62 \t 0 \t 723 \t 41\n",
      "   True:  9 \t 0 \t 30 \t 2 \t 19 \t 7 \t 17 \t 452 \t 3 \t 11 \t 468\n",
      "\n",
      "Zoom  1.75\n",
      "10000/10000 [==============================] - 1s 143us/step\n",
      "   Results\n",
      "   Loss,acc 2.2316860569000245 0.4839\n",
      "   True:  0 \t 323 \t 1 \t 0 \t 0 \t 10 \t 33 \t 519 \t 1 \t 0 \t 93\n",
      "   True:  1 \t 0 \t 1116 \t 1 \t 2 \t 1 \t 0 \t 1 \t 4 \t 3 \t 7\n",
      "   True:  2 \t 0 \t 10 \t 564 \t 30 \t 20 \t 2 \t 232 \t 55 \t 107 \t 12\n",
      "   True:  3 \t 0 \t 4 \t 24 \t 316 \t 1 \t 48 \t 420 \t 7 \t 14 \t 176\n",
      "   True:  4 \t 0 \t 18 \t 2 \t 6 \t 436 \t 37 \t 438 \t 0 \t 7 \t 38\n",
      "   True:  5 \t 0 \t 2 \t 5 \t 112 \t 1 \t 629 \t 129 \t 1 \t 1 \t 12\n",
      "   True:  6 \t 0 \t 8 \t 0 \t 145 \t 168 \t 173 \t 330 \t 6 \t 0 \t 128\n",
      "   True:  7 \t 0 \t 123 \t 75 \t 6 \t 78 \t 8 \t 247 \t 376 \t 13 \t 102\n",
      "   True:  8 \t 0 \t 74 \t 61 \t 85 \t 6 \t 38 \t 290 \t 11 \t 298 \t 111\n",
      "   True:  9 \t 0 \t 38 \t 3 \t 27 \t 28 \t 30 \t 427 \t 3 \t 2 \t 451\n",
      "\n",
      "Zoom  2.0\n",
      "10000/10000 [==============================] - 1s 141us/step\n",
      "   Results\n",
      "   Loss,acc 2.343675131225586 0.3575\n",
      "   True:  0 \t 82 \t 1 \t 0 \t 1 \t 13 \t 77 \t 696 \t 0 \t 0 \t 110\n",
      "   True:  1 \t 0 \t 1116 \t 1 \t 5 \t 1 \t 3 \t 1 \t 2 \t 0 \t 6\n",
      "   True:  2 \t 0 \t 8 \t 444 \t 89 \t 20 \t 6 \t 330 \t 61 \t 45 \t 29\n",
      "   True:  3 \t 0 \t 9 \t 15 \t 219 \t 0 \t 32 \t 464 \t 6 \t 4 \t 261\n",
      "   True:  4 \t 0 \t 17 \t 0 \t 20 \t 384 \t 66 \t 444 \t 0 \t 6 \t 45\n",
      "   True:  5 \t 0 \t 3 \t 1 \t 205 \t 2 \t 407 \t 254 \t 0 \t 0 \t 20\n",
      "   True:  6 \t 0 \t 9 \t 0 \t 195 \t 212 \t 148 \t 284 \t 0 \t 0 \t 110\n",
      "   True:  7 \t 0 \t 65 \t 65 \t 18 \t 88 \t 29 \t 322 \t 168 \t 8 \t 265\n",
      "   True:  8 \t 0 \t 112 \t 41 \t 87 \t 6 \t 41 \t 489 \t 7 \t 57 \t 134\n",
      "   True:  9 \t 0 \t 37 \t 1 \t 46 \t 32 \t 73 \t 405 \t 1 \t 0 \t 414\n"
     ]
    }
   ],
   "source": [
    "trained_network = load_model('fully_trained_model_cnn.h5')\n",
    "\n",
    "for zoom in [1.0,1.25,1.5,1.75,2.0]:\n",
    "    print()\n",
    "    print(\"Zoom \",zoom)\n",
    "    imgList = []\n",
    "    count = 0\n",
    "    for img in test_images[:]:\n",
    "        if random.uniform(0.0,1.0) > 0.5:\n",
    "            Zoom = zoom\n",
    "        else:\n",
    "            Zoom = -zoom\n",
    "\n",
    "        trans_image = transform_image(img,tx=0.0,ty=0.0,zoom=Zoom,rotation=0.0,shear=0.0)\n",
    "        imgList.append(trans_image)\n",
    "#\n",
    "# Convert to np array\n",
    "    npa_images = np.asarray(imgList, dtype=np.float32)\n",
    "    #npa_images = npa_images.reshape((npa_images.shape[0],28*28))\n",
    "#\n",
    "    smear_loss,smear_acc,smear_cf = getPerformance(trained_network,npa_images,test_labels_cat,test_labels)\n",
    "    print(\"   Results\")\n",
    "    print(\"   Loss,acc\",smear_loss,smear_acc)\n",
    "    for trueClass in range(10):\n",
    "        print(\"   True: \",trueClass,end=\"\")\n",
    "        for predClass in range(10):\n",
    "            print(\" \\t\",smear_cf[trueClass][predClass],end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda 5.2) [python/3.6-conda5.2]",
   "language": "python",
   "name": "sys_python36conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
